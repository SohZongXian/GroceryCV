{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d82fd-d6ea-4808-9116-627641b62b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40404852-e2bf-447e-baa4-908611737336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7a65a9-4be0-4844-8529-0743081aeb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#checking for device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961f50d-2ef5-42d5-9512-7c832d464d10",
   "metadata": {},
   "source": [
    "## Augmentation object creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58e1926-e005-48c5-87b5-fe60c7735982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbc9ad7-ac38-4800-8956-24cba296d718",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec8a66-ba12-4ea7-a5d2-817a89e2024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check image\n",
    "#Path for training and testing directory\n",
    "train_path='C:/Users/user/Documents/GitHub/GroceryCV/GroceryStoreDataset-master/dataset_pt/train'\n",
    "test_path='C:/Users/user/Documents/GitHub/GroceryCV/GroceryStoreDataset-master/dataset_pt/test'\n",
    "\n",
    "train_img =  torchvision.datasets.ImageFolder(root = train_path,transform=transformer)\n",
    "test_img = torchvision.datasets.ImageFolder(root = test_path,transform=transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2652310-c8c3-4fc5-a7cd-986abcaf2ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_transformed_image(dataset):\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size = 6, shuffle=True)\n",
    "    batch = next(iter(loader))\n",
    "    images, labels = batch\n",
    "    \n",
    "    grid = torchvision.utils.make_grid(images, nrow = 3)\n",
    "    plt.figure(figsize = (11,11))\n",
    "    plt.imshow(np.transpose(grid, (1,2,0)))\n",
    "    print('Labels:', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39483b1e-ab93-413b-8285-43675ab54e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_transformed_image(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a284801b-6722-43f4-a314-ca6bdd931492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "\n",
    "#Path for training and testing directory\n",
    "train_path='C:/Users/user/Documents/GitHub/GroceryCV/GroceryStoreDataset-master/dataset_pt/train'\n",
    "test_path='C:/Users/user/Documents/GitHub/GroceryCV/GroceryStoreDataset-master/dataset_pt/test'\n",
    "\n",
    "train_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")\n",
    "\n",
    "# train_loader=DataLoader(\n",
    "#     train_img,\n",
    "#     batch_size=64, shuffle=True\n",
    "# )\n",
    "# test_loader=DataLoader(\n",
    "#     test_img,\n",
    "#     batch_size=32, shuffle=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69fad86-71c3-41a3-be03-3e817195b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43c7326-708b-4c39-acc8-706526905c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fruit', 'Packages', 'Vegetables']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f10f43a-0544-41c1-a0ff-ae7376118b00",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a43e5cd-a562-41de-96c1-d90ca3c3491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=ConvNet(num_classes=len(classes)).to(device)\n",
    "model = models.resnet50()\n",
    "model.load_state_dict(torch.load('resnet50-0676ba61.pth'))\n",
    "\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "    \n",
    "model.fc = torch.nn.Linear(in_features=2048,out_features=len(classes),bias=True)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31abf333-1d7e-444a-9d95-a33845992851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "643daa42-703a-4bd1-886b-598a3a89528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d0788b1-00d8-4a23-b16d-1379fd86c81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1746 165\n"
     ]
    }
   ],
   "source": [
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65aac053-84e0-4b88-9253-fb4830e8913f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(0.5906) Train Accuracy: 0.761168384879725 Test Accuracy: 0.8181818181818182\n",
      "Epoch: 1 Train Loss: tensor(0.3103) Train Accuracy: 0.8900343642611683 Test Accuracy: 0.9212121212121213\n",
      "Epoch: 2 Train Loss: tensor(0.2259) Train Accuracy: 0.93184421534937 Test Accuracy: 0.9212121212121213\n",
      "Epoch: 3 Train Loss: tensor(0.2047) Train Accuracy: 0.936426116838488 Test Accuracy: 0.9212121212121213\n",
      "Epoch: 4 Train Loss: tensor(0.1949) Train Accuracy: 0.9312714776632303 Test Accuracy: 0.9393939393939394\n",
      "Epoch: 5 Train Loss: tensor(0.1833) Train Accuracy: 0.9375715922107675 Test Accuracy: 0.9575757575757575\n",
      "Epoch: 6 Train Loss: tensor(0.1500) Train Accuracy: 0.9564719358533792 Test Accuracy: 0.9333333333333333\n",
      "Epoch: 7 Train Loss: tensor(0.1389) Train Accuracy: 0.9587628865979382 Test Accuracy: 0.9454545454545454\n",
      "Epoch: 8 Train Loss: tensor(0.1333) Train Accuracy: 0.9639175257731959 Test Accuracy: 0.9454545454545454\n",
      "Epoch: 9 Train Loss: tensor(0.1420) Train Accuracy: 0.9524627720504009 Test Accuracy: 0.9515151515151515\n",
      "Time taken: 137.68203973770142\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "    \n",
    "    # Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    test_accuracy=test_accuracy/test_count\n",
    "    \n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Time taken:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc76999-20d6-4c8e-9963-24571983af4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
