{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d82fd-d6ea-4808-9116-627641b62b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "40404852-e2bf-447e-baa4-908611737336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a7a65a9-4be0-4844-8529-0743081aeb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#checking for device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961f50d-2ef5-42d5-9512-7c832d464d10",
   "metadata": {},
   "source": [
    "## Augmentation object creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d58e1926-e005-48c5-87b5-fe60c7735982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbc9ad7-ac38-4800-8956-24cba296d718",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a284801b-6722-43f4-a314-ca6bdd931492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "\n",
    "#Path for training and testing directory\n",
    "train_path='C:/Users/user/Documents/GitHub/GroceryCV/GroceryStoreDataset-master/dataset/train'\n",
    "test_path='C:/Users/user/Documents/GitHub/GroceryCV/GroceryStoreDataset-master/dataset/test'\n",
    "\n",
    "train_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e69fad86-71c3-41a3-be03-3e817195b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f43c7326-708b-4c39-acc8-706526905c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple', 'Asparagus', 'Aubergine', 'Avocado', 'Banana', 'Cabbage', 'Carrots', 'Cucumber', 'Garlic', 'Ginger', 'Juice', 'Kiwi', 'Leek', 'Lemon', 'Lime', 'Mango', 'Milk', 'Mushroom', 'Nectarine', 'Onion', 'Orange', 'Papaya', 'Passion-Fruit', 'Peach', 'Pear', 'Pepper', 'Pineapple', 'Plum', 'Potato', 'Sour-Milk', 'Soy-Milk', 'Tomato', 'Yoghurt', 'Zucchini']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f10f43a-0544-41c1-a0ff-ae7376118b00",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3ab93cff-4f4b-4ab4-b2c1-74d699c88abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=len(classes)):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Output size after convolution filter\n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        #Input shape= (256,3,150,150)\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Shape= (256,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (256,12,150,150)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (256,12,75,75)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (256,20,75,75)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (256,32,75,75)\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Feed foward function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "            \n",
    "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "            \n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd69214-09ed-41bb-b67b-e0492a53958f",
   "metadata": {},
   "source": [
    "## Final Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7a43e5cd-a562-41de-96c1-d90ca3c3491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=len(classes)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "31abf333-1d7e-444a-9d95-a33845992851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.001) \n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "643daa42-703a-4bd1-886b-598a3a89528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9d0788b1-00d8-4a23-b16d-1379fd86c81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1239 165\n"
     ]
    }
   ],
   "source": [
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "65aac053-84e0-4b88-9253-fb4830e8913f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(5.8442) Train Accuracy: 0.6957223567393059 Test Accuracy: 0.36363636363636365\n",
      "Epoch: 1 Train Loss: tensor(3.5038) Train Accuracy: 0.7562550443906376 Test Accuracy: 0.36363636363636365\n",
      "Epoch: 2 Train Loss: tensor(2.4093) Train Accuracy: 0.8272800645682001 Test Accuracy: 0.47878787878787876\n",
      "Epoch: 3 Train Loss: tensor(1.7898) Train Accuracy: 0.8603712671509282 Test Accuracy: 0.4484848484848485\n",
      "Epoch: 4 Train Loss: tensor(1.5784) Train Accuracy: 0.864406779661017 Test Accuracy: 0.49696969696969695\n",
      "Epoch: 5 Train Loss: tensor(2.6369) Train Accuracy: 0.8184019370460048 Test Accuracy: 0.38181818181818183\n",
      "Epoch: 6 Train Loss: tensor(1.4897) Train Accuracy: 0.8514931396287329 Test Accuracy: 0.45454545454545453\n",
      "Epoch: 7 Train Loss: tensor(1.8725) Train Accuracy: 0.8426150121065376 Test Accuracy: 0.45454545454545453\n",
      "Epoch: 8 Train Loss: tensor(1.1290) Train Accuracy: 0.8853914447134786 Test Accuracy: 0.47878787878787876\n",
      "Epoch: 9 Train Loss: tensor(1.2279) Train Accuracy: 0.8684422921711057 Test Accuracy: 0.4484848484848485\n",
      "Time taken: 63.01218342781067\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "    \n",
    "    # Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    test_accuracy=test_accuracy/test_count\n",
    "    \n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Time taken:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1317ea95-9c9a-4e79-85c4-d11fd3f114d2",
   "metadata": {},
   "source": [
    "## Model tuning\n",
    "##### https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e603608e-520a-4559-a32c-9c8ae3a10943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.06060606060606061Model_training_time: 78.63084483146667Learning_rate: 0.1 Weight_decay: 0.1\n",
      "Accuracy: 0.06060606060606061Model_training_time: 67.68916320800781Learning_rate: 0.1 Weight_decay: 0.01\n",
      "Accuracy: 0.06060606060606061Model_training_time: 64.28623294830322Learning_rate: 0.1 Weight_decay: 0.001\n",
      "Accuracy: 0.06060606060606061Model_training_time: 64.16207265853882Learning_rate: 0.1 Weight_decay: 0.0001\n",
      "Accuracy: 0.024242424242424242Model_training_time: 64.36404061317444Learning_rate: 0.01 Weight_decay: 0.1\n",
      "Accuracy: 0.3393939393939394Model_training_time: 66.21559810638428Learning_rate: 0.01 Weight_decay: 0.01\n",
      "Accuracy: 0.40606060606060607Model_training_time: 64.43703746795654Learning_rate: 0.01 Weight_decay: 0.001\n",
      "Accuracy: 0.4303030303030303Model_training_time: 64.25464534759521Learning_rate: 0.01 Weight_decay: 0.0001\n",
      "Accuracy: 0.45454545454545453Model_training_time: 64.52485823631287Learning_rate: 0.001 Weight_decay: 0.1\n",
      "Accuracy: 0.47878787878787876Model_training_time: 63.91080927848816Learning_rate: 0.001 Weight_decay: 0.01\n",
      "Accuracy: 0.503030303030303Model_training_time: 64.611154794693Learning_rate: 0.001 Weight_decay: 0.001\n",
      "Accuracy: 0.4727272727272727Model_training_time: 63.46263027191162Learning_rate: 0.001 Weight_decay: 0.0001\n",
      "Accuracy: 0.45454545454545453Model_training_time: 63.357770681381226Learning_rate: 0.0001 Weight_decay: 0.1\n",
      "Accuracy: 0.47878787878787876Model_training_time: 63.57286596298218Learning_rate: 0.0001 Weight_decay: 0.01\n",
      "Accuracy: 0.509090909090909Model_training_time: 64.87432098388672Learning_rate: 0.0001 Weight_decay: 0.001\n",
      "Accuracy: 0.5333333333333333Model_training_time: 63.992669343948364Learning_rate: 0.0001 Weight_decay: 0.0001\n"
     ]
    }
   ],
   "source": [
    "model=ConvNet(num_classes=len(classes)).to(device)\n",
    "\n",
    "learning_rate_params = [0.1, 0.01, 0.001, 0.0001]\n",
    "weight_decay_params = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "for x in learning_rate_params:\n",
    "    for j in weight_decay_params:\n",
    "        optimizer=Adam(model.parameters(),lr=x,weight_decay=j) \n",
    "        loss_function=nn.CrossEntropyLoss()\n",
    "        num_epochs=10\n",
    "        start = time.time()\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            #Evaluation and training on training dataset\n",
    "            model.train()\n",
    "            train_accuracy=0.0\n",
    "            train_loss=0.0\n",
    "\n",
    "            for i, (images,labels) in enumerate(train_loader):\n",
    "                if torch.cuda.is_available():\n",
    "                    images=Variable(images.cuda())\n",
    "                    labels=Variable(labels.cuda())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs=model(images)\n",
    "                loss=loss_function(outputs,labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "                train_loss+= loss.cpu().data*images.size(0)\n",
    "                _,prediction=torch.max(outputs.data,1)\n",
    "\n",
    "                train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "\n",
    "            train_accuracy=train_accuracy/train_count\n",
    "            train_loss=train_loss/train_count\n",
    "\n",
    "\n",
    "            # Evaluation on testing dataset\n",
    "            model.eval()\n",
    "\n",
    "            test_accuracy=0.0\n",
    "            for i, (images,labels) in enumerate(test_loader):\n",
    "                if torch.cuda.is_available():\n",
    "                    images=Variable(images.cuda())\n",
    "                    labels=Variable(labels.cuda())\n",
    "\n",
    "                outputs=model(images)\n",
    "                _,prediction=torch.max(outputs.data,1)\n",
    "                test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "\n",
    "            test_accuracy=test_accuracy/test_count\n",
    "            best_test_accuracy = 0 \n",
    "            if test_accuracy > best_test_accuracy:\n",
    "                best_test_accuracy = test_accuracy\n",
    "        end = time.time()\n",
    "        temp_df = pd.DataFrame({\n",
    "            \"accuracy\":[best_test_accuracy],\n",
    "            \"model_training_time\":[end - start],\n",
    "            \"learning_rate\": [x],\n",
    "            \"weight_decay\":[j]\n",
    "        \n",
    "        })\n",
    "        print('Accuracy: '+str(best_test_accuracy)+'Model_training_time: '+str(end - start)+'Learning_rate: '+str(x)+' Weight_decay: '+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e8ccc-b498-460d-b529-d3e1b8071922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
