{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d82fd-d6ea-4808-9116-627641b62b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40404852-e2bf-447e-baa4-908611737336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a65a9-4be0-4844-8529-0743081aeb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961f50d-2ef5-42d5-9512-7c832d464d10",
   "metadata": {},
   "source": [
    "## Augmentation object creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e1926-e005-48c5-87b5-fe60c7735982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbc9ad7-ac38-4800-8956-24cba296d718",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0e99a-5e77-4065-8427-a079cd58dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check image\n",
    "#Path for training and testing directory\n",
    "train_path='C:/Users/user/Documents/GitHub/GroceryCV/GroceryStoreDataset-master/dataset_pt/train'\n",
    "test_path='C:/Users/user/Documents/GitHub/GroceryCV/GroceryStoreDataset-master/dataset_pt/test'\n",
    "\n",
    "train_img =  torchvision.datasets.ImageFolder(root = train_path,transform=transformer)\n",
    "test_img = torchvision.datasets.ImageFolder(root = test_path,transform=transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1749f8fc-9a0b-4844-8b4e-b7683aedaa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_transformed_image(dataset):\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size = 6, shuffle=True)\n",
    "    batch = next(iter(loader))\n",
    "    images, labels = batch\n",
    "    \n",
    "    grid = torchvision.utils.make_grid(images, nrow = 3)\n",
    "    plt.figure(figsize = (11,11))\n",
    "    plt.imshow(np.transpose(grid, (1,2,0)))\n",
    "    print('Labels:', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe471dd-831e-43c2-81fb-0faa271a2331",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_transformed_image(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a284801b-6722-43f4-a314-ca6bdd931492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "\n",
    "#Path for training and testing directory\n",
    "train_path='C:/Users/user/Documents/GitHub/GroceryCV/GroceryStoreDataset-master/dataset_pt/train'\n",
    "test_path='C:/Users/user/Documents/GitHub/GroceryCV/GroceryStoreDataset-master/dataset_pt/test'\n",
    "\n",
    "train_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")\n",
    "\n",
    "# train_loader=DataLoader(\n",
    "#     train_img,\n",
    "#     batch_size=64, shuffle=True\n",
    "# )\n",
    "# test_loader=DataLoader(\n",
    "#     test_img,\n",
    "#     batch_size=32, shuffle=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69fad86-71c3-41a3-be03-3e817195b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c7326-708b-4c39-acc8-706526905c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f10f43a-0544-41c1-a0ff-ae7376118b00",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab93cff-4f4b-4ab4-b2c1-74d699c88abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=len(classes)):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Output size after convolution filter\n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        #Input shape= (256,3,150,150)\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Shape= (256,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (256,12,150,150)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (256,12,75,75)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (256,20,75,75)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (256,32,75,75)\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Feed foward function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "            \n",
    "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "            \n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd69214-09ed-41bb-b67b-e0492a53958f",
   "metadata": {},
   "source": [
    "## Final Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a43e5cd-a562-41de-96c1-d90ca3c3491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=len(classes)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31abf333-1d7e-444a-9d95-a33845992851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.001) \n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643daa42-703a-4bd1-886b-598a3a89528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0788b1-00d8-4a23-b16d-1379fd86c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aac053-84e0-4b88-9253-fb4830e8913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "    \n",
    "    # Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    test_accuracy=test_accuracy/test_count\n",
    "    \n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Time taken:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1317ea95-9c9a-4e79-85c4-d11fd3f114d2",
   "metadata": {},
   "source": [
    "## Model tuning\n",
    "##### https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e603608e-520a-4559-a32c-9c8ae3a10943",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=len(classes)).to(device)\n",
    "\n",
    "learning_rate_params = [0.1, 0.01, 0.001, 0.0001]\n",
    "weight_decay_params = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "for x in learning_rate_params:\n",
    "    for j in weight_decay_params:\n",
    "        optimizer=Adam(model.parameters(),lr=x,weight_decay=j) \n",
    "        loss_function=nn.CrossEntropyLoss()\n",
    "        num_epochs=10\n",
    "        start = time.time()\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            #Evaluation and training on training dataset\n",
    "            model.train()\n",
    "            train_accuracy=0.0\n",
    "            train_loss=0.0\n",
    "\n",
    "            for i, (images,labels) in enumerate(train_loader):\n",
    "                if torch.cuda.is_available():\n",
    "                    images=Variable(images.cuda())\n",
    "                    labels=Variable(labels.cuda())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs=model(images)\n",
    "                loss=loss_function(outputs,labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "                train_loss+= loss.cpu().data*images.size(0)\n",
    "                _,prediction=torch.max(outputs.data,1)\n",
    "\n",
    "                train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "\n",
    "            train_accuracy=train_accuracy/train_count\n",
    "            train_loss=train_loss/train_count\n",
    "\n",
    "\n",
    "            # Evaluation on testing dataset\n",
    "            model.eval()\n",
    "\n",
    "            test_accuracy=0.0\n",
    "            for i, (images,labels) in enumerate(test_loader):\n",
    "                if torch.cuda.is_available():\n",
    "                    images=Variable(images.cuda())\n",
    "                    labels=Variable(labels.cuda())\n",
    "\n",
    "                outputs=model(images)\n",
    "                _,prediction=torch.max(outputs.data,1)\n",
    "                test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "\n",
    "            test_accuracy=test_accuracy/test_count\n",
    "            best_test_accuracy = 0 \n",
    "            if test_accuracy > best_test_accuracy:\n",
    "                best_test_accuracy = test_accuracy\n",
    "        end = time.time()\n",
    "        temp_df = pd.DataFrame({\n",
    "            \"accuracy\":[best_test_accuracy],\n",
    "            \"model_training_time\":[end - start],\n",
    "            \"learning_rate\": [x],\n",
    "            \"weight_decay\":[j]\n",
    "        \n",
    "        })\n",
    "        print('Accuracy: '+str(best_test_accuracy)+'Model_training_time: '+str(end - start)+'Learning_rate: '+str(x)+' Weight_decay: '+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e8ccc-b498-460d-b529-d3e1b8071922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
